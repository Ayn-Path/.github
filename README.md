# Ayn-Path: AI-Driven Smart Indoor Navigation System with AR for the Visually Impaired

<img width="746" height="776" alt="AynPath_Prototype" src="https://github.com/user-attachments/assets/515efdb7-f636-4576-95d9-a29a3edc2573" />

## Overview

Navigating inside large buildings is often difficult for people with disabilities, especially those who are blind or have low vision. Most navigation tools today are designed for outdoor use and depend on GPS, which is unreliable indoors because of weak satellite signals. This makes it challenging to move through complex spaces such as campuses, shopping malls, or office buildings. Existing assistive apps usually focus on one specific feature, like detecting objects, reading text aloud, or guiding someone across a street. To get the full navigation experience, users often have to switch between several different apps, which can be inconvenient and overwhelming.

Ayn-Path was created to bring these needs together in a single application. By combining artificial intelligence and augmented reality, the system offers accurate indoor localization, detects obstacles commonly found in buildings, and provides real-time guidance. Directions are delivered through clear audio cues, gentle haptic feedback, and AR-based visual arrows. The goal of Ayn-Path is to give blind and visually impaired people more independence and confidence when moving through indoor environments, making navigation safer, smoother, and easier.

## Repositories Details

### (1) Dataset
* Video
* Frame
* Features

### (2)  
### (1) 
### (1) 
*
*
*
*
